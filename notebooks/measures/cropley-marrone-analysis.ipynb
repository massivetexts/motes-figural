{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropley and Marrone report accuracy and confusion matrices, but no measures that account for class imbalances. Reverse engineering some of those measures here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_class_metrics(confusion_matrix: pd.DataFrame):\n",
    "    metrics = {}\n",
    "    for class_name in confusion_matrix.columns:\n",
    "        true_positives = confusion_matrix.loc[class_name, class_name]\n",
    "        false_positives = confusion_matrix[class_name].sum() - true_positives\n",
    "        false_negatives = confusion_matrix.loc[class_name].sum() - true_positives\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        \n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        metrics[class_name] = {\"precision\": precision, \"recall\": recall, \"F1\": f1}\n",
    "\n",
    "    return pd.DataFrame(metrics).T\n",
    "\n",
    "def raw_to_df(raw):\n",
    "    rows = []\n",
    "    for line in raw.split('\\n'):\n",
    "        line = re.sub('\\s(\\d)', r',\\1', line.strip())\n",
    "        rows.append(line.split(','))\n",
    "    df= pd.DataFrame(rows)\n",
    "    df.columns = ['actual_class'] + df[0].tolist()\n",
    "    df = df.set_index('actual_class')\n",
    "    df = df.astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_metrics(confusion_matrix: pd.DataFrame):\n",
    "    metrics = {}\n",
    "    total_true_positives = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    for class_name in confusion_matrix.columns:\n",
    "        true_positives = confusion_matrix.loc[class_name, class_name]\n",
    "        false_positives = confusion_matrix[class_name].sum() - true_positives\n",
    "        false_negatives = confusion_matrix.loc[class_name].sum() - true_positives\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        \n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        total_true_positives += true_positives\n",
    "        total_false_positives += false_positives\n",
    "        total_false_negatives += false_negatives\n",
    "        \n",
    "        metrics[class_name] = {\"precision\": precision, \"recall\": recall, \"F1\": f1}\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "\n",
    "    micro_precision = total_true_positives / (total_true_positives + total_false_positives)\n",
    "    micro_recall = total_true_positives / (total_true_positives + total_false_negatives)\n",
    "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n",
    "\n",
    "    macro_precision = metrics_df[\"precision\"].mean()\n",
    "    macro_recall = metrics_df[\"recall\"].mean()\n",
    "    macro_f1 = 2 * (macro_precision * macro_recall) / (macro_precision + macro_recall)\n",
    "\n",
    "    overall_metrics = pd.DataFrame({\n",
    "        \"micro\": {\"precision\": micro_precision, \"recall\": micro_recall, \"F1\": micro_f1},\n",
    "        \"macro\": {\"precision\": macro_precision, \"recall\": macro_recall, \"F1\": macro_f1},\n",
    "    }).T\n",
    "\n",
    "    return metrics_df, overall_metrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting, somewhat puzzling choice is that the authors narrowed the bins, dropping data at the cusp of the classes. I think that perhaps they were imagining a use case where the test is scored with easily differentiated boundaries aligned with the banded norms of the test, but this had the effect of throwing out the 'hard' data and the edge of the bands. Thankfully, their Model 5 ran the same exercise without dropping data, making it more sound and easier to evaluate. I'll start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615384615384616"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test set size 65\n",
      "Accuracy 0.8615384615384616\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "A   0.900000  1.000000  0.947368\n",
       "B   1.000000  0.833333  0.909091\n",
       "C   0.826087  0.950000  0.883721\n",
       "D   0.750000  0.600000  0.666667\n",
       "E   0.875000  0.875000  0.875000\n",
       "F   0.750000  0.750000  0.750000\n",
       "G   1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.871584</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.864908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall        F1\n",
       "micro   0.861538  0.861538  0.861538\n",
       "macro   0.871584  0.858333  0.864908"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model5 = '''A 9 0 0 0 0 0 0\n",
    "B 1 10 1 0 0 0 0\n",
    "C 0 0 19 1 0 0 0\n",
    "D 0 0 3 6 1 0 0\n",
    "E 0 0 0 0 7 1 0\n",
    "F 0 0 0 1 0 3 0\n",
    "G 0 0 0 0 0 0 2'''\n",
    "df = raw_to_df(model5)\n",
    "print(\"Overall test set size\", df.values.sum())\n",
    "print(\"Accuracy\", df.values.diagonal().sum() / df.values.sum())\n",
    "class_metrics, overall_metrics = calculate_metrics(df)\n",
    "display(class_metrics)\n",
    "display(overall_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted, the testset size is 65 here, which approximately matches their reporting of 15% of 414."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.099999999999994"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "414*.15"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 - this was where they split the continuous variable into 5 bins. About 1/4 of the data was dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test set size 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Very Low</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very High</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision    recall        F1\n",
       "Very Low    1.000000  1.000000  1.000000\n",
       "Low         1.000000  0.888889  0.941176\n",
       "Medium      0.875000  0.933333  0.903226\n",
       "High        1.000000  1.000000  1.000000\n",
       "Very High   0.909091  0.909091  0.909091"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.956818</td>\n",
       "      <td>0.946263</td>\n",
       "      <td>0.951511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall        F1\n",
       "micro   0.937500  0.937500  0.937500\n",
       "macro   0.956818  0.946263  0.951511"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = '''Very Low 9 0 0 0 0\n",
    "Low 0 8 1 0 0\n",
    "Medium 0 0 14 0 1\n",
    "High 0 0 0 4 0\n",
    "Very High 0 0 1 0 10'''\n",
    "df = raw_to_df(model3)\n",
    "print(\"Overall test set size\", df.sum().sum())\n",
    "class_metrics, overall_metrics = calculate_metrics(df)\n",
    "display(class_metrics)\n",
    "display(overall_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4 - Where the continuous variable is binned into 7 classes. As seen here, about half of the harder-to-classify data (32/65) was removed by the narrowed bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test set size 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        F1\n",
       "A   1.000000  0.888889  0.941176\n",
       "B   0.833333  1.000000  0.909091\n",
       "C   1.000000  1.000000  1.000000\n",
       "D   1.000000  1.000000  1.000000\n",
       "E   0.750000  1.000000  0.857143\n",
       "F   1.000000  0.750000  0.857143\n",
       "G   1.000000  1.000000  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>micro</th>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro</th>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.944428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall        F1\n",
       "micro   0.939394  0.939394  0.939394\n",
       "macro   0.940476  0.948413  0.944428"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4 = '''A 8 1 0 0 0 0 0\n",
    "B 0 5 0 0 0 0 0\n",
    "C 0 0 5 0 0 0 0\n",
    "D 0 0 0 5 0 0 0\n",
    "E 0 0 0 0 3 0 0\n",
    "F 0 0 0 0 1 3 0\n",
    "G 0 0 0 0 0 0 2'''\n",
    "df = raw_to_df(model4)\n",
    "print(\"Overall test set size\", df.sum().sum())\n",
    "class_metrics, overall_metrics = calculate_metrics(df)\n",
    "display(class_metrics)\n",
    "display(overall_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
